{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dae41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ü§ñ ENTRA√éNEMENT DU MOD√àLE ASL OPTIMIS√â POUR MOBILE\n",
      "======================================================================\n",
      "============================================================\n",
      "üìä CHARGEMENT DES DONN√âES\n",
      "============================================================\n",
      "\n",
      "‚úÖ Dataset charg√© avec succ√®s!\n",
      "   üìè Dimensions: 1500000 lignes √ó 13 colonnes\n",
      "\n",
      "üè∑Ô∏è  Classes: 40\n",
      "   ['a', 'b', 'bad', 'c', 'd', 'deaf', 'e', 'f', 'fine', 'g', 'good', 'goodbye', 'h', 'hello', 'hungry', 'i', 'j', 'k', 'l', 'm', 'me', 'n', 'no', 'o', 'p', 'please', 'q', 'r', 's', 'sorry', 't', 'thankyou', 'u', 'v', 'w', 'x', 'y', 'yes', 'you', 'z']\n",
      "\n",
      "üìà R√âPARTITION PAR CLASSE:\n",
      "   a              :  37500 √©chantillons\n",
      "   b              :  37500 √©chantillons\n",
      "   bad            :  37500 √©chantillons\n",
      "   c              :  37500 √©chantillons\n",
      "   d              :  37500 √©chantillons\n",
      "   deaf           :  37500 √©chantillons\n",
      "   e              :  37500 √©chantillons\n",
      "   f              :  37500 √©chantillons\n",
      "   fine           :  37500 √©chantillons\n",
      "   g              :  37500 √©chantillons\n",
      "   good           :  37500 √©chantillons\n",
      "   goodbye        :  37500 √©chantillons\n",
      "   h              :  37500 √©chantillons\n",
      "   hello          :  37500 √©chantillons\n",
      "   hungry         :  37500 √©chantillons\n",
      "   i              :  37500 √©chantillons\n",
      "   j              :  37500 √©chantillons\n",
      "   k              :  37500 √©chantillons\n",
      "   l              :  37500 √©chantillons\n",
      "   m              :  37500 √©chantillons\n",
      "   me             :  37500 √©chantillons\n",
      "   n              :  37500 √©chantillons\n",
      "   no             :  37500 √©chantillons\n",
      "   o              :  37500 √©chantillons\n",
      "   p              :  37500 √©chantillons\n",
      "   please         :  37500 √©chantillons\n",
      "   q              :  37500 √©chantillons\n",
      "   r              :  37500 √©chantillons\n",
      "   s              :  37500 √©chantillons\n",
      "   sorry          :  37500 √©chantillons\n",
      "   t              :  37500 √©chantillons\n",
      "   thankyou       :  37500 √©chantillons\n",
      "   u              :  37500 √©chantillons\n",
      "   v              :  37500 √©chantillons\n",
      "   w              :  37500 √©chantillons\n",
      "   x              :  37500 √©chantillons\n",
      "   y              :  37500 √©chantillons\n",
      "   yes            :  37500 √©chantillons\n",
      "   you            :  37500 √©chantillons\n",
      "   z              :  37500 √©chantillons\n",
      "\n",
      "‚úÖ Aucune valeur manquante!\n",
      "\n",
      "============================================================\n",
      "üîß PR√âTRAITEMENT DES DONN√âES\n",
      "============================================================\n",
      "\n",
      "üìä Features (X): (1500000, 11)\n",
      "üè∑Ô∏è  Labels (y): (1500000,)\n",
      "\n",
      "üî¢ Encodage des labels:\n",
      "   'a' ‚Üí 0\n",
      "   'b' ‚Üí 1\n",
      "   'bad' ‚Üí 2\n",
      "   'c' ‚Üí 3\n",
      "   'd' ‚Üí 4\n",
      "   ... (40 classes au total)\n",
      "\n",
      "‚úÖ Normalisation appliqu√©e (StandardScaler)\n",
      "\n",
      "üìä S√âPARATION TRAIN/TEST:\n",
      "   üéØ Train: 1200000 √©chantillons\n",
      "   üß™ Test:  300000 √©chantillons\n",
      "\n",
      "============================================================\n",
      "üöÄ ENTRA√éNEMENT DU MOD√àLE OPTIMIS√â MOBILE\n",
      "============================================================\n",
      "\n",
      "üå≥ Configuration du mod√®le:\n",
      "   üì¶ Nombre d'arbres: 30 (au lieu de 100)\n",
      "   üìè Profondeur max: 12\n",
      "   üîπ Min samples split: 10\n",
      "   üîπ Min samples leaf: 4\n",
      "\n",
      "   ‚úÖ Optimis√© pour r√©duire la taille du mod√®le ONNX\n",
      "\n",
      "‚è≥ Entra√Ænement en cours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   46.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entra√Ænement termin√©!\n",
      "\n",
      "üîÑ Validation crois√©e (5-fold)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   34.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   45.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   37.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   43.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   38.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Scores: ['0.9115', '0.9162', '0.9142', '0.9126', '0.9095']\n",
      "   Moyenne: 0.9128 (¬±0.0023)\n",
      "\n",
      "============================================================\n",
      "üìà √âVALUATION DU MOD√àLE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ ACCURACY: 0.9098 (90.98%)\n",
      "\n",
      "üìä RAPPORT DE CLASSIFICATION:\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.89      0.98      0.93      7500\n",
      "           b       0.94      0.99      0.96      7500\n",
      "         bad       0.83      0.68      0.75      7500\n",
      "           c       0.97      0.81      0.88      7500\n",
      "           d       0.76      0.94      0.84      7500\n",
      "        deaf       0.87      0.84      0.86      7500\n",
      "           e       0.81      0.91      0.86      7500\n",
      "           f       1.00      1.00      1.00      7500\n",
      "        fine       0.88      0.95      0.91      7500\n",
      "           g       0.94      1.00      0.97      7500\n",
      "        good       0.92      0.65      0.76      7500\n",
      "     goodbye       0.88      0.86      0.87      7500\n",
      "           h       1.00      1.00      1.00      7500\n",
      "       hello       0.84      0.84      0.84      7500\n",
      "      hungry       0.99      0.96      0.98      7500\n",
      "           i       0.95      1.00      0.97      7500\n",
      "           j       0.99      0.93      0.96      7500\n",
      "           k       0.93      0.98      0.95      7500\n",
      "           l       0.96      0.99      0.97      7500\n",
      "           m       0.98      0.98      0.98      7500\n",
      "          me       0.90      0.80      0.85      7500\n",
      "           n       0.98      0.87      0.92      7500\n",
      "          no       0.99      0.96      0.97      7500\n",
      "           o       0.87      0.91      0.89      7500\n",
      "           p       1.00      0.99      1.00      7500\n",
      "      please       0.91      0.97      0.94      7500\n",
      "           q       0.99      0.98      0.98      7500\n",
      "           r       0.89      0.98      0.93      7500\n",
      "           s       0.83      0.83      0.83      7500\n",
      "       sorry       0.95      0.96      0.95      7500\n",
      "           t       0.88      0.92      0.90      7500\n",
      "    thankyou       0.60      0.83      0.70      7500\n",
      "           u       0.93      0.94      0.94      7500\n",
      "           v       0.97      0.93      0.95      7500\n",
      "           w       0.99      0.99      0.99      7500\n",
      "           x       0.91      0.85      0.88      7500\n",
      "           y       0.99      1.00      1.00      7500\n",
      "         yes       0.94      0.82      0.88      7500\n",
      "         you       0.78      0.83      0.80      7500\n",
      "           z       0.97      0.79      0.87      7500\n",
      "\n",
      "    accuracy                           0.91    300000\n",
      "   macro avg       0.91      0.91      0.91    300000\n",
      "weighted avg       0.91      0.91      0.91    300000\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìä CR√âATION DES VISUALISATIONS\n",
      "============================================================\n",
      "   ‚úÖ Matrice de confusion: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\confusion_matrix_mobile.png\n",
      "   ‚úÖ Importance des features: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\feature_importance_mobile.png\n",
      "\n",
      "============================================================\n",
      "üíæ SAUVEGARDE DU MOD√àLE MOBILE\n",
      "============================================================\n",
      "   ‚úÖ Mod√®le: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\asl_model_mobile.pkl\n",
      "      üì¶ Taille: 45.08 MB\n",
      "   ‚úÖ Scaler: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\scaler.pkl\n",
      "   ‚úÖ Label Encoder: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\label_encoder.pkl\n",
      "   ‚úÖ M√©tadonn√©es: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\model_metadata.json\n",
      "\n",
      "============================================================\n",
      "üß™ TEST DE PR√âDICTION\n",
      "============================================================\n",
      "\n",
      "üìä √âchantillon #204378:\n",
      "   Features: [0.00875109 1.7337771  1.34574205 0.95359009 0.65426917]...\n",
      "\n",
      "üéØ Vraie classe: sorry\n",
      "ü§ñ Pr√©diction: sorry\n",
      "   ‚úÖ CORRECT\n",
      "\n",
      "üìä Top 3 probabilit√©s:\n",
      "   1. sorry          : 0.9199 (91.99%)\n",
      "   2. hungry         : 0.0388 (3.88%)\n",
      "   3. z              : 0.0085 (0.85%)\n",
      "\n",
      "======================================================================\n",
      "‚ú® ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS !\n",
      "======================================================================\n",
      "\n",
      "üìä R√©sum√©:\n",
      "   üéØ Accuracy: 0.9098 (90.98%)\n",
      "   üìÅ Mod√®le sauvegard√©: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\n",
      "   üì¶ Optimis√© pour conversion ONNX\n",
      "   üå≥ Arbres: 30 (r√©duit pour mobile)\n",
      "   üìè Profondeur max: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION OPTIMIS√âE POUR MOBILE\n",
    "# ============================================\n",
    "\n",
    "DATASET_PATH = r\"C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\asl_dataset_complete.csv\"\n",
    "MODEL_OUTPUT_DIR = r\"C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\"\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    'flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5',\n",
    "    'GYRx', 'GYRy', 'GYRz',\n",
    "    'ACCx', 'ACCy', 'ACCz'\n",
    "]\n",
    "\n",
    "TEST_SIZE = 0.2 \n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ‚ö° PARAM√àTRES OPTIMIS√âS POUR MOBILE\n",
    "N_ESTIMATORS = 30        # ‚úÖ R√©duit de 100 ‚Üí 30 (3x plus l√©ger)\n",
    "MAX_DEPTH = 12           # ‚úÖ Limite la profondeur des arbres\n",
    "MIN_SAMPLES_SPLIT = 10   # ‚úÖ √âvite le surapprentissage\n",
    "MIN_SAMPLES_LEAF = 4     # ‚úÖ R√©duit la complexit√©\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 1: CHARGER LES DONN√âES\n",
    "# ============================================\n",
    "\n",
    "def load_and_explore_data():\n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä CHARGEMENT DES DONN√âES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset charg√© avec succ√®s!\")\n",
    "    print(f\"   üìè Dimensions: {df.shape[0]} lignes √ó {df.shape[1]} colonnes\")\n",
    "    print(f\"\\nüè∑Ô∏è  Classes: {df['label'].nunique()}\")\n",
    "    print(f\"   {sorted(df['label'].unique())}\")\n",
    "    \n",
    "    print(f\"\\nüìà R√âPARTITION PAR CLASSE:\")\n",
    "    label_counts = df['label'].value_counts().sort_index()\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"   {label:15s}: {count:6d} √©chantillons\")\n",
    "    \n",
    "    missing = df[FEATURE_COLUMNS].isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  VALEURS MANQUANTES:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Aucune valeur manquante!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 2: PR√âTRAITEMENT\n",
    "# ============================================\n",
    "\n",
    "def preprocess_data(df):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîß PR√âTRAITEMENT DES DONN√âES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    X = df[FEATURE_COLUMNS].values\n",
    "    y = df['label'].values\n",
    "    \n",
    "    print(f\"\\nüìä Features (X): {X.shape}\")\n",
    "    print(f\"üè∑Ô∏è  Labels (y): {y.shape}\")\n",
    "    \n",
    "    # Encoder les labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    print(f\"\\nüî¢ Encodage des labels:\")\n",
    "    for i, label in enumerate(label_encoder.classes_[:5]):\n",
    "        print(f\"   '{label}' ‚Üí {i}\")\n",
    "    print(f\"   ... ({len(label_encoder.classes_)} classes au total)\")\n",
    "    \n",
    "    # Normaliser\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Normalisation appliqu√©e (StandardScaler)\")\n",
    "    \n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_encoded, \n",
    "        test_size=TEST_SIZE, \n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä S√âPARATION TRAIN/TEST:\")\n",
    "    print(f\"   üéØ Train: {X_train.shape[0]} √©chantillons\")\n",
    "    print(f\"   üß™ Test:  {X_test.shape[0]} √©chantillons\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, label_encoder\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 3: ENTRA√éNER LE MOD√àLE OPTIMIS√â\n",
    "# ============================================\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üöÄ ENTRA√éNEMENT DU MOD√àLE OPTIMIS√â MOBILE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ‚ö° Mod√®le optimis√© pour mobile\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=N_ESTIMATORS,           # Moins d'arbres\n",
    "        max_depth=MAX_DEPTH,                 # Profondeur limit√©e\n",
    "        min_samples_split=MIN_SAMPLES_SPLIT, # N≈ìuds plus larges\n",
    "        min_samples_leaf=MIN_SAMPLES_LEAF,   # Feuilles plus larges\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüå≥ Configuration du mod√®le:\")\n",
    "    print(f\"   üì¶ Nombre d'arbres: {N_ESTIMATORS} (au lieu de 100)\")\n",
    "    print(f\"   üìè Profondeur max: {MAX_DEPTH}\")\n",
    "    print(f\"   üîπ Min samples split: {MIN_SAMPLES_SPLIT}\")\n",
    "    print(f\"   üîπ Min samples leaf: {MIN_SAMPLES_LEAF}\")\n",
    "    print(f\"\\n   ‚úÖ Optimis√© pour r√©duire la taille du mod√®le ONNX\")\n",
    "    \n",
    "    print(f\"\\n‚è≥ Entra√Ænement en cours...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"‚úÖ Entra√Ænement termin√©!\")\n",
    "    \n",
    "    # Validation crois√©e\n",
    "    print(f\"\\nüîÑ Validation crois√©e (5-fold)...\")\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(f\"   Scores: {[f'{s:.4f}' for s in cv_scores]}\")\n",
    "    print(f\"   Moyenne: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 4: √âVALUER LE MOD√àLE\n",
    "# ============================================\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_encoder):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìà √âVALUATION DU MOD√àLE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nüéØ ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìä RAPPORT DE CLASSIFICATION:\")\n",
    "    print(\"-\"*60)\n",
    "    report = classification_report(\n",
    "        y_test, y_pred, \n",
    "        target_names=label_encoder.classes_,\n",
    "        zero_division=0\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, report, cm\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 5: VISUALISATION\n",
    "# ============================================\n",
    "\n",
    "def visualize_results(cm, label_encoder, feature_importance, model_dir):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä CR√âATION DES VISUALISATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Matrice de confusion\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title('Matrice de Confusion (Mod√®le Mobile)')\n",
    "    plt.ylabel('Vraie classe')\n",
    "    plt.xlabel('Classe pr√©dite')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cm_path = os.path.join(model_dir, 'confusion_matrix_mobile.png')\n",
    "    plt.savefig(cm_path, dpi=150)\n",
    "    print(f\"   ‚úÖ Matrice de confusion: {cm_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Importance des features\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    feature_names = FEATURE_COLUMNS\n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    plt.bar(range(len(feature_importance)), feature_importance[indices])\n",
    "    plt.xticks(range(len(feature_importance)), \n",
    "               [feature_names[i] for i in indices], \n",
    "               rotation=45, ha='right')\n",
    "    plt.title('Importance des Features (Mod√®le Mobile)')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.xlabel('Features')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fi_path = os.path.join(model_dir, 'feature_importance_mobile.png')\n",
    "    plt.savefig(fi_path, dpi=150)\n",
    "    print(f\"   ‚úÖ Importance des features: {fi_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 6: SAUVEGARDER LE MOD√àLE\n",
    "# ============================================\n",
    "\n",
    "def save_model(model, scaler, label_encoder, model_dir):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üíæ SAUVEGARDE DU MOD√àLE MOBILE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Sauvegarder le mod√®le\n",
    "    model_path = os.path.join(model_dir, 'asl_model_mobile.pkl')\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # Taille du fichier\n",
    "    size_mb = os.path.getsize(model_path) / (1024 * 1024)\n",
    "    print(f\"   ‚úÖ Mod√®le: {model_path}\")\n",
    "    print(f\"      üì¶ Taille: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Scaler\n",
    "    scaler_path = os.path.join(model_dir, 'scaler.pkl')\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(f\"   ‚úÖ Scaler: {scaler_path}\")\n",
    "    \n",
    "    # Label encoder\n",
    "    encoder_path = os.path.join(model_dir, 'label_encoder.pkl')\n",
    "    with open(encoder_path, 'wb') as f:\n",
    "        pickle.dump(label_encoder, f)\n",
    "    print(f\"   ‚úÖ Label Encoder: {encoder_path}\")\n",
    "    \n",
    "    # M√©tadonn√©es\n",
    "    metadata = {\n",
    "        'feature_columns': FEATURE_COLUMNS,\n",
    "        'classes': label_encoder.classes_.tolist(),\n",
    "        'n_classes': len(label_encoder.classes_),\n",
    "        'n_features': len(FEATURE_COLUMNS),\n",
    "        'model_type': 'RandomForestClassifier',\n",
    "        'n_estimators': N_ESTIMATORS,\n",
    "        'max_depth': MAX_DEPTH,\n",
    "        'optimized_for': 'mobile',\n",
    "        'target_format': 'ONNX'\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(model_dir, 'model_metadata.json')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    print(f\"   ‚úÖ M√©tadonn√©es: {metadata_path}\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 7: TEST DE PR√âDICTION\n",
    "# ============================================\n",
    "\n",
    "def test_prediction(model, scaler, label_encoder, X_test, y_test):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üß™ TEST DE PR√âDICTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    sample = X_test[idx:idx+1]\n",
    "    true_label = label_encoder.classes_[y_test[idx]]\n",
    "    \n",
    "    prediction = model.predict(sample)\n",
    "    predicted_label = label_encoder.classes_[prediction[0]]\n",
    "    \n",
    "    probabilities = model.predict_proba(sample)[0]\n",
    "    \n",
    "    print(f\"\\nüìä √âchantillon #{idx}:\")\n",
    "    print(f\"   Features: {sample[0][:5]}...\")\n",
    "    print(f\"\\nüéØ Vraie classe: {true_label}\")\n",
    "    print(f\"ü§ñ Pr√©diction: {predicted_label}\")\n",
    "    print(f\"   {'‚úÖ CORRECT' if true_label == predicted_label else '‚ùå INCORRECT'}\")\n",
    "    \n",
    "    print(f\"\\nüìä Top 3 probabilit√©s:\")\n",
    "    top_3_idx = np.argsort(probabilities)[-3:][::-1]\n",
    "    for i, idx in enumerate(top_3_idx, 1):\n",
    "        label = label_encoder.classes_[idx]\n",
    "        prob = probabilities[idx]\n",
    "        print(f\"   {i}. {label:15s}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION PRINCIPALE\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ü§ñ ENTRA√éNEMENT DU MOD√àLE ASL OPTIMIS√â POUR MOBILE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Charger\n",
    "    df = load_and_explore_data()\n",
    "    \n",
    "    # 2. Pr√©traiter\n",
    "    X_train, X_test, y_train, y_test, scaler, label_encoder = preprocess_data(df)\n",
    "    \n",
    "    # 3. Entra√Æner (mod√®le optimis√©)\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # 4. √âvaluer\n",
    "    accuracy, report, cm = evaluate_model(model, X_test, y_test, label_encoder)\n",
    "    \n",
    "    # 5. Cr√©er le dossier\n",
    "    os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # 6. Visualiser\n",
    "    feature_importance = model.feature_importances_\n",
    "    visualize_results(cm, label_encoder, feature_importance, MODEL_OUTPUT_DIR)\n",
    "    \n",
    "    # 7. Sauvegarder\n",
    "    save_model(model, scaler, label_encoder, MODEL_OUTPUT_DIR)\n",
    "    \n",
    "    # 8. Test\n",
    "    test_prediction(model, scaler, label_encoder, X_test, y_test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚ú® ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS !\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nüìä R√©sum√©:\")\n",
    "    print(f\"   üéØ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"   üìÅ Mod√®le sauvegard√©: {MODEL_OUTPUT_DIR}\")\n",
    "    print(f\"   üì¶ Optimis√© pour conversion ONNX\")\n",
    "    print(f\"   üå≥ Arbres: {N_ESTIMATORS} (r√©duit pour mobile)\")\n",
    "    print(f\"   üìè Profondeur max: {MAX_DEPTH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
