{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce135b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ CONVERSION DU MOD√àLE ASL POUR MOBILE\n",
      "================================================================================\n",
      "======================================================================\n",
      "üîÑ CONVERSION DU MOD√àLE EN ONNX\n",
      "======================================================================\n",
      "\n",
      "üì¶ Chargement des fichiers...\n",
      "   ‚úÖ Mod√®le charg√©: RandomForestClassifier(max_depth=12, min_samples_leaf=4, min_samples_split=10,\n",
      "                       n_estimators=30, n_jobs=-1, random_state=42, verbose=1)\n",
      "   ‚úÖ Scaler charg√©\n",
      "   ‚úÖ Label Encoder charg√©\n",
      "      Classes: 40\n",
      "\n",
      "üîß Configuration ONNX:\n",
      "   Shape d'entr√©e: [None, 11] (batch variable, 11 features)\n",
      "\n",
      "‚è≥ Conversion en cours...\n",
      "   ‚úÖ Conversion r√©ussie!\n",
      "\n",
      "üíæ Mod√®le ONNX sauvegard√©:\n",
      "   üìÅ Chemin: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\asl_model.onnx\n",
      "   üì¶ Taille: 31.97 MB\n",
      "\n",
      "üîç V√©rification du mod√®le ONNX...\n",
      "   ‚úÖ Mod√®le ONNX valide!\n",
      "\n",
      "======================================================================\n",
      "üß™ TEST DU MOD√àLE ONNX\n",
      "======================================================================\n",
      "\n",
      "‚è≥ Chargement du mod√®le ONNX...\n",
      "   ‚úÖ Session ONNX cr√©√©e\n",
      "\n",
      "üìä Informations du mod√®le:\n",
      "   Entr√©e: float_input\n",
      "   Shape: [None, 11]\n",
      "   Type: tensor(float)\n",
      "   Sorties: ['label', 'probabilities']\n",
      "\n",
      "üé≤ G√©n√©ration de donn√©es de test...\n",
      "   Shape: (1, 11)\n",
      "   Donn√©es: [-2.112338   -1.3550664   0.32506925 -0.33582434 -0.5564693 ]... (premiers 5 valeurs)\n",
      "\n",
      "‚è≥ Pr√©diction en cours...\n",
      "\n",
      "üéØ R√âSULTATS:\n",
      "   Classe pr√©dite: hungry (ID: 14)\n",
      "   Confiance: 0.2022 (20.22%)\n",
      "\n",
      "üìä Top 3 probabilit√©s:\n",
      "   1. hungry         : 0.2022 (20.22%)\n",
      "   2. sorry          : 0.1995 (19.95%)\n",
      "   3. q              : 0.1707 (17.07%)\n",
      "\n",
      "‚úÖ Test r√©ussi! Le mod√®le ONNX fonctionne correctement.\n",
      "\n",
      "======================================================================\n",
      "üìù CR√âATION DU FICHIER DE TEST\n",
      "======================================================================\n",
      "   ‚úÖ Fichier de test cr√©√©: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\test_samples.json\n",
      "   üìä 4 √©chantillons de test\n",
      "\n",
      "======================================================================\n",
      "üì± INSTRUCTIONS POUR REACT NATIVE\n",
      "======================================================================\n",
      "\n",
      "‚úÖ √âTAPES D'INT√âGRATION:\n",
      "\n",
      "1Ô∏è‚É£ Installer ONNX Runtime React Native:\n",
      "   npm install onnxruntime-react-native\n",
      "\n",
      "2Ô∏è‚É£ Copier les fichiers dans votre projet:\n",
      "   - Copier C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\asl_model.onnx ‚Üí assets/models/asl_model.onnx\n",
      "   - Copier C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\\test_samples.json ‚Üí assets/test_samples.json\n",
      "\n",
      "3Ô∏è‚É£ Code exemple React Native:\n",
      "\n",
      "import { InferenceSession } from 'onnxruntime-react-native';\n",
      "\n",
      "// Charger le mod√®le\n",
      "const session = await InferenceSession.create('asl_model.onnx');\n",
      "\n",
      "// Pr√©parer les donn√©es (11 features normalis√©es)\n",
      "const sensorData = [\n",
      "  flex1, flex2, flex3, flex4, flex5,  // 0-100\n",
      "  gyrX, gyrY, gyrZ,                    // ¬±1 rad/s\n",
      "  accX, accY, accZ                     // ¬±10 m/s¬≤\n",
      "];\n",
      "\n",
      "// Normaliser les donn√©es (utiliser les m√™mes stats que le scaler)\n",
      "const normalizedData = new Float32Array(sensorData);\n",
      "\n",
      "// Pr√©diction\n",
      "const feeds = { float_input: normalizedData };\n",
      "const results = await session.run(feeds);\n",
      "\n",
      "// R√©sultats\n",
      "const label = results.output_label.data[0];\n",
      "const probabilities = results.output_probability.data;\n",
      "\n",
      "4Ô∏è‚É£ Classes reconnues:\n",
      "   a, b, bad, c, d, deaf, e, f, fine, g\n",
      "   ... (40 classes au total)\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANT:\n",
      "   - Les donn√©es doivent √™tre normalis√©es avant la pr√©diction\n",
      "   - Utiliser Float32Array pour les entr√©es\n",
      "   - Le mod√®le attend exactement 11 features\n",
      "\n",
      "üì¶ Taille du mod√®le: 31.97 MB\n",
      "   Compatible avec Android et iOS!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "‚ú® CONVERSION TERMIN√âE AVEC SUCC√àS !\n",
      "================================================================================\n",
      "\n",
      "üìÅ Fichiers g√©n√©r√©s dans: C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\n",
      "   ‚úÖ asl_model.onnx\n",
      "   ‚úÖ test_samples.json\n",
      "\n",
      "üéØ Le mod√®le est pr√™t pour React Native!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "MODEL_DIR = r\"C:\\Users\\sersi\\Desktop\\projet_SE_et_IOT\\HandSense_project\\model_mobile\"\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, \"asl_model_mobile.pkl\")\n",
    "scaler_path = os.path.join(MODEL_DIR, \"scaler.pkl\")\n",
    "encoder_path = os.path.join(MODEL_DIR, \"label_encoder.pkl\")\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 1: CONVERTIR EN ONNX\n",
    "# ============================================\n",
    "\n",
    "def convert_to_onnx():\n",
    "    \"\"\"\n",
    "    Convertit le mod√®le sklearn en format ONNX\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîÑ CONVERSION DU MOD√àLE EN ONNX\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Charger le mod√®le\n",
    "    print(\"\\nüì¶ Chargement des fichiers...\")\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Mod√®le charg√©: {model}\")\n",
    "    \n",
    "    with open(scaler_path, \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Scaler charg√©\")\n",
    "    \n",
    "    with open(encoder_path, \"rb\") as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    print(f\"   ‚úÖ Label Encoder charg√©\")\n",
    "    print(f\"      Classes: {len(label_encoder.classes_)}\")\n",
    "    \n",
    "    # D√©finir l'entr√©e ONNX\n",
    "    print(f\"\\nüîß Configuration ONNX:\")\n",
    "    print(f\"   Shape d'entr√©e: [None, 11] (batch variable, 11 features)\")\n",
    "    initial_type = [('float_input', FloatTensorType([None, 11]))]\n",
    "    \n",
    "    # Convertir\n",
    "    try:\n",
    "        print(f\"\\n‚è≥ Conversion en cours...\")\n",
    "        onnx_model = convert_sklearn(\n",
    "            model, \n",
    "            initial_types=initial_type,\n",
    "            target_opset=12,  # Version ONNX compatible\n",
    "            options={\n",
    "                'zipmap': False,  # D√©sactive ZipMap (r√©duit la taille)\n",
    "                'nocl': True      # Pas de transformation de classe\n",
    "            }\n",
    "        )\n",
    "        print(f\"   ‚úÖ Conversion r√©ussie!\")\n",
    "        \n",
    "    except MemoryError as e:\n",
    "        print(f\"\\n‚ùå ERREUR: M√©moire insuffisante\")\n",
    "        print(f\"   Le mod√®le est encore trop volumineux.\")\n",
    "        print(f\"   Solutions:\")\n",
    "        print(f\"   1. R√©duire n_estimators √† 20\")\n",
    "        print(f\"   2. R√©duire max_depth √† 10\")\n",
    "        print(f\"   3. Utiliser TFLite au lieu d'ONNX\")\n",
    "        raise e\n",
    "    \n",
    "    # Sauvegarder\n",
    "    onnx_path = os.path.join(MODEL_DIR, \"asl_model.onnx\")\n",
    "    with open(onnx_path, \"wb\") as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "    \n",
    "    # Taille du fichier\n",
    "    size_mb = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "    print(f\"\\nüíæ Mod√®le ONNX sauvegard√©:\")\n",
    "    print(f\"   üìÅ Chemin: {onnx_path}\")\n",
    "    print(f\"   üì¶ Taille: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # V√©rifier le mod√®le\n",
    "    print(f\"\\nüîç V√©rification du mod√®le ONNX...\")\n",
    "    try:\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "        print(f\"   ‚úÖ Mod√®le ONNX valide!\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Avertissement: {e}\")\n",
    "    \n",
    "    return onnx_path\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 2: TESTER LE MOD√àLE ONNX\n",
    "# ============================================\n",
    "\n",
    "def test_onnx_model(onnx_path):\n",
    "    \"\"\"\n",
    "    Teste le mod√®le ONNX avec des donn√©es al√©atoires\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üß™ TEST DU MOD√àLE ONNX\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Charger le label encoder pour afficher les noms\n",
    "    with open(encoder_path, \"rb\") as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    \n",
    "    # Cr√©er une session ONNX Runtime\n",
    "    print(f\"\\n‚è≥ Chargement du mod√®le ONNX...\")\n",
    "    session = ort.InferenceSession(onnx_path)\n",
    "    print(f\"   ‚úÖ Session ONNX cr√©√©e\")\n",
    "    \n",
    "    # Informations sur le mod√®le\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output_names = [output.name for output in session.get_outputs()]\n",
    "    \n",
    "    print(f\"\\nüìä Informations du mod√®le:\")\n",
    "    print(f\"   Entr√©e: {input_name}\")\n",
    "    print(f\"   Shape: {session.get_inputs()[0].shape}\")\n",
    "    print(f\"   Type: {session.get_inputs()[0].type}\")\n",
    "    print(f\"   Sorties: {output_names}\")\n",
    "    \n",
    "    # Cr√©er des donn√©es de test (valeurs normalis√©es)\n",
    "    print(f\"\\nüé≤ G√©n√©ration de donn√©es de test...\")\n",
    "    test_data = np.random.randn(1, 11).astype(np.float32)  # 1 √©chantillon, 11 features\n",
    "    print(f\"   Shape: {test_data.shape}\")\n",
    "    print(f\"   Donn√©es: {test_data[0][:5]}... (premiers 5 valeurs)\")\n",
    "    \n",
    "    # Pr√©diction\n",
    "    print(f\"\\n‚è≥ Pr√©diction en cours...\")\n",
    "    inputs = {input_name: test_data}\n",
    "    outputs = session.run(output_names, inputs)\n",
    "    \n",
    "    # R√©sultats\n",
    "    label = outputs[0][0]  # Classe pr√©dite\n",
    "    probabilities = outputs[1][0]  # Probabilit√©s\n",
    "    \n",
    "    predicted_class = label_encoder.classes_[label]\n",
    "    \n",
    "    print(f\"\\nüéØ R√âSULTATS:\")\n",
    "    print(f\"   Classe pr√©dite: {predicted_class} (ID: {label})\")\n",
    "    print(f\"   Confiance: {probabilities[label]:.4f} ({probabilities[label]*100:.2f}%)\")\n",
    "    \n",
    "    # Top 3 pr√©dictions\n",
    "    print(f\"\\nüìä Top 3 probabilit√©s:\")\n",
    "    top_3_idx = np.argsort(probabilities)[-3:][::-1]\n",
    "    for i, idx in enumerate(top_3_idx, 1):\n",
    "        class_name = label_encoder.classes_[idx]\n",
    "        prob = probabilities[idx]\n",
    "        print(f\"   {i}. {class_name:15s}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Test r√©ussi! Le mod√®le ONNX fonctionne correctement.\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 3: CR√âER UN FICHIER DE TEST POUR REACT NATIVE\n",
    "# ============================================\n",
    "\n",
    "def create_test_file():\n",
    "    \"\"\"\n",
    "    Cr√©e un fichier JSON avec des donn√©es de test pour React Native\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìù CR√âATION DU FICHIER DE TEST\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Charger label encoder\n",
    "    with open(encoder_path, \"rb\") as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    \n",
    "    # Cr√©er des donn√©es de test\n",
    "    test_samples = []\n",
    "    \n",
    "    # Exemple 1: Geste de repos (tous les capteurs √† 0)\n",
    "    test_samples.append({\n",
    "        \"name\": \"Rest Position\",\n",
    "        \"features\": [0.0] * 11,\n",
    "        \"expected_class\": \"rest\"\n",
    "    })\n",
    "    \n",
    "    # Exemple 2: Valeurs al√©atoires normalis√©es\n",
    "    for i in range(3):\n",
    "        sample = {\n",
    "            \"name\": f\"Random Sample {i+1}\",\n",
    "            \"features\": np.random.randn(11).tolist(),\n",
    "            \"expected_class\": \"unknown\"\n",
    "        }\n",
    "        test_samples.append(sample)\n",
    "    \n",
    "    # Sauvegarder\n",
    "    test_file = os.path.join(MODEL_DIR, \"test_samples.json\")\n",
    "    import json\n",
    "    with open(test_file, 'w') as f:\n",
    "        json.dump({\n",
    "            \"samples\": test_samples,\n",
    "            \"classes\": label_encoder.classes_.tolist(),\n",
    "            \"n_features\": 11,\n",
    "            \"feature_names\": [\n",
    "                'flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5',\n",
    "                'GYRx', 'GYRy', 'GYRz',\n",
    "                'ACCx', 'ACCy', 'ACCz'\n",
    "            ]\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"   ‚úÖ Fichier de test cr√©√©: {test_file}\")\n",
    "    print(f\"   üìä {len(test_samples)} √©chantillons de test\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION 4: AFFICHER LES INSTRUCTIONS REACT NATIVE\n",
    "# ============================================\n",
    "\n",
    "def show_react_native_instructions(onnx_path, label_encoder):\n",
    "    \"\"\"\n",
    "    Affiche les instructions pour int√©grer le mod√®le dans React Native\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üì± INSTRUCTIONS POUR REACT NATIVE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "‚úÖ √âTAPES D'INT√âGRATION:\n",
    "\n",
    "1Ô∏è‚É£ Installer ONNX Runtime React Native:\n",
    "   npm install onnxruntime-react-native\n",
    "\n",
    "2Ô∏è‚É£ Copier les fichiers dans votre projet:\n",
    "   - Copier {onnx_path} ‚Üí assets/models/asl_model.onnx\n",
    "   - Copier {os.path.join(MODEL_DIR, 'test_samples.json')} ‚Üí assets/test_samples.json\n",
    "\n",
    "3Ô∏è‚É£ Code exemple React Native:\n",
    "\n",
    "import {{ InferenceSession }} from 'onnxruntime-react-native';\n",
    "\n",
    "// Charger le mod√®le\n",
    "const session = await InferenceSession.create('asl_model.onnx');\n",
    "\n",
    "// Pr√©parer les donn√©es (11 features normalis√©es)\n",
    "const sensorData = [\n",
    "  flex1, flex2, flex3, flex4, flex5,  // 0-100\n",
    "  gyrX, gyrY, gyrZ,                    // ¬±1 rad/s\n",
    "  accX, accY, accZ                     // ¬±10 m/s¬≤\n",
    "];\n",
    "\n",
    "// Normaliser les donn√©es (utiliser les m√™mes stats que le scaler)\n",
    "const normalizedData = new Float32Array(sensorData);\n",
    "\n",
    "// Pr√©diction\n",
    "const feeds = {{ float_input: normalizedData }};\n",
    "const results = await session.run(feeds);\n",
    "\n",
    "// R√©sultats\n",
    "const label = results.output_label.data[0];\n",
    "const probabilities = results.output_probability.data;\n",
    "\n",
    "4Ô∏è‚É£ Classes reconnues:\n",
    "   {', '.join(label_encoder.classes_.tolist()[:10])}\n",
    "   ... ({len(label_encoder.classes_)} classes au total)\n",
    "\n",
    "‚ö†Ô∏è  IMPORTANT:\n",
    "   - Les donn√©es doivent √™tre normalis√©es avant la pr√©diction\n",
    "   - Utiliser Float32Array pour les entr√©es\n",
    "   - Le mod√®le attend exactement 11 features\n",
    "\n",
    "üì¶ Taille du mod√®le: {os.path.getsize(onnx_path) / (1024 * 1024):.2f} MB\n",
    "   Compatible avec Android et iOS!\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# FONCTION PRINCIPALE\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Pipeline complet de conversion\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ CONVERSION DU MOD√àLE ASL POUR MOBILE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # 1. Convertir en ONNX\n",
    "        onnx_path = convert_to_onnx()\n",
    "        \n",
    "        # 2. Tester le mod√®le\n",
    "        test_onnx_model(onnx_path)\n",
    "        \n",
    "        # 3. Cr√©er fichier de test\n",
    "        create_test_file()\n",
    "        \n",
    "        # 4. Afficher instructions (charger label_encoder ici)\n",
    "        with open(encoder_path, \"rb\") as f:\n",
    "            label_encoder = pickle.load(f)\n",
    "        show_react_native_instructions(onnx_path, label_encoder)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚ú® CONVERSION TERMIN√âE AVEC SUCC√àS !\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nüìÅ Fichiers g√©n√©r√©s dans: {MODEL_DIR}\")\n",
    "        print(f\"   ‚úÖ asl_model.onnx\")\n",
    "        print(f\"   ‚úÖ test_samples.json\")\n",
    "        print(f\"\\nüéØ Le mod√®le est pr√™t pour React Native!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERREUR: {e}\")\n",
    "        print(f\"\\nüí° Solutions:\")\n",
    "        print(f\"   1. R√©entra√Æner avec n_estimators=20\")\n",
    "        print(f\"   2. Utiliser TFLite: pip install tensorflow\")\n",
    "        print(f\"   3. V√©rifier la m√©moire disponible\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
